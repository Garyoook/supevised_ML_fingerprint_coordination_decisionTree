import random
import sys

import numpy as np
# used for formatting the output, not in evaluation implementation.
from texttable import Texttable

import dt

FOLD_NUM = 10
CLASS_NUM = 4


def evaluate(test_db, trained_tree):
    '''
    :param test_db: The test dataset
    :param trained_tree: The decision tree to evaluate
    :return: the accuracy of the confusion matrix generated by the decision tree
    '''
    confusion_matrix = get_confusion_matrix(test_db, trained_tree)
    total_diagonal = 0
    for i in range(CLASS_NUM):
        total_diagonal += confusion_matrix[i][i]
    try:
        return total_diagonal / len(test_db)
    except ZeroDivisionError:
        print('the sum of values in the confusion matrix is 0, please check.')


def cross_validation(all_db_list):
    label_list = ["index", "accuracy", "precision", "recall", "f1",
                  "maximal depth"]  # set up heading for eva luation result table
    class_list = ["room1", "room2", "room3", "room4"]  # set up heading for the confusion matrix
    macro_table = Texttable()
    macro_table.header(label_list)
    for roomi in range(1, CLASS_NUM + 1):
        # total accuracy, precision, recall, f1 scores for all 10 folds of validation
        total_accuracy = 0
        total_precision = 0
        total_recall = 0
        total_f1 = 0
        total_matrix = np.zeros((CLASS_NUM, CLASS_NUM))
        max_depth = 0
        db_size = len(all_db_list)
        step = db_size // FOLD_NUM
        arr = []
        arr.append(label_list)
        for start in range(0, db_size, step):
            # start and end position of test set
            end = start + step
            test_db, training_db = separate_data(all_db, start, end, db_size)
            d_tree, depth = dt.decision_tree_learning(training_db, 0)
            if depth > max_depth:
                max_depth = depth
            accuracy = get_accuracy(test_db, d_tree, roomi)
            precision = get_precision(test_db, d_tree, roomi)
            recall = get_recall(test_db, d_tree, roomi)
            f1 = get_f1(test_db, d_tree, roomi)
            total_accuracy += accuracy
            total_precision += precision
            total_recall += recall
            total_f1 += f1
            data = get_confusion_matrix(test_db, d_tree)
            total_matrix = np.array(data) + np.array(total_matrix)
            col = [str(start // step + 1), str(accuracy), str(precision), str(recall), str(f1), str(depth)]
            arr.append(col)
            data.insert(0, class_list)
        t = Texttable()
        t.add_rows(arr)
        print('Evaluation result for room' + str(roomi) + ' is: ')
        average_result = ["average of room " + str(roomi), str(total_accuracy / FOLD_NUM),
                          str(total_precision / FOLD_NUM),
                          str(total_recall / FOLD_NUM), str(total_f1 / FOLD_NUM),
                          str(max_depth) + ' (Note: this is max depth rather than avg depth)']
        macro_table.add_row(average_result)
        t.add_row(average_result)
        print(t.draw())  # print "index", "accuracy", "precision", "recall", "f1" of each fold
        average_matrix = np.array(total_matrix) / FOLD_NUM
        m = Texttable()
        m.header(class_list)
        for i in range(CLASS_NUM):
            m.add_row(average_matrix[i])
        print('average confusion matrix for room ' + str(roomi) + ' is: ')
        print(m.draw())  # print average confusion matrix
    print(macro_table.draw())


def separate_data(all_db_list, start, end, size):
    """
    separates the data into (training + validation) set and test set / training set and test set
    :param all_db_list: all the data
    :param start: start index of test/validation set
    :param end: end index of test/validation set
    :param size: size of all data
    :return: a pair (test_set, training_set) or (test_set, training_validation_set)
    """
    test_set = all_db_list[start:end]  # test or validation set
    # training set or (training + validation) set
    if start == 0:
        training_set = all_db_list[end:]
    elif end == size:
        training_set = all_db_list[:start]
    else:
        training_set = np.concatenate((all_db_list[:start], all_db_list[end:]))
    return test_set, training_set


def predict(test_data, d_tree):
    """
    :return: classified label
    """
    if d_tree['leaf']:
        return d_tree['value']
    wifi_number = int(d_tree['attribute'].split('_')[1])
    signal_value = d_tree['value']
    if test_data[wifi_number - 1] > signal_value:
        return predict(test_data, d_tree['left'])
    else:
        return predict(test_data, d_tree['right'])


def get_confusion_matrix(test_db, trained_tree):
    """
    :return: confusion matrix generated by the decision tree and the test dataset
    """
    # decision_tree format: python dictionary: {'attribute', 'value', 'left', 'right', 'leaf'}
    wifi_number = int(trained_tree['attribute'].split('_')[1])
    signal_value = trained_tree['value']
    confusion_matrix = [[0] * CLASS_NUM for _ in range(CLASS_NUM)]

    for rowi in test_db:
        actual_signal = rowi[wifi_number - 1]
        actual_room = int(rowi[-1])
        if actual_signal > signal_value:
            predicted_room = int(predict(rowi, trained_tree['left']))
        else:
            predicted_room = int(predict(rowi, trained_tree['right']))
        confusion_matrix[actual_room - 1][predicted_room - 1] += 1
    return confusion_matrix


def get_recall(test_db, trained_tree, class_num):
    attributes = get_tp_fp_tn_fn(test_db, trained_tree, class_num)
    tp = attributes[0]
    fn = attributes[3]
    try:
        return tp / (tp + fn)
    except ZeroDivisionError:
        print("tp + fn result in a sum of 0, please check the classifier:")


def get_precision(test_db, trained_tree, class_num):
    attributes = get_tp_fp_tn_fn(test_db, trained_tree, class_num)
    tp = attributes[0]
    fp = attributes[1]
    try:
        return tp / (tp + fp)
    except ZeroDivisionError:
        print("tp + fp result in a sum of 0, please check the classifier:")


def get_f1(test_db, trained_tree, class_num):
    precision = get_precision(test_db, trained_tree, class_num)
    recall = get_recall(test_db, trained_tree, class_num)
    try:
        return 2 * precision * recall / (precision + recall)
    except ZeroDivisionError:
        print("precision and recall are both 0, please check the classifier:")


def get_accuracy(test_db, trained_tree, class_num):
    attributes = get_tp_fp_tn_fn(test_db, trained_tree, class_num)
    tp = attributes[0]
    tn = attributes[2]
    try:
        return (tp + tn) / len(test_db)
    except ZeroDivisionError:
        print("tp + tn + fp + fn result in a sum of 0, please check the classifier:")


def get_tp_fp_tn_fn(test_db, trained_tree, class_num):
    confusion_matrix = get_confusion_matrix(test_db, trained_tree)
    tp = confusion_matrix[class_num - 1][class_num - 1]
    fp = sum(confusion_matrix[i][class_num - 1] for i in range(CLASS_NUM) if i != class_num - 1)
    tn = sum(confusion_matrix[i][i] for i in range(CLASS_NUM) if i != class_num - 1)
    fn = sum(confusion_matrix[class_num - 1][i] for i in range(CLASS_NUM) if i != class_num - 1)
    return [tp, fp, tn, fn]


if __name__ == '__main__':
    inputfile = sys.argv[1]
    all_db = np.loadtxt(inputfile)
    all_db_list = []
    for row in all_db:
        all_db_list.append(row)
    random.shuffle(all_db_list)
    cross_validation(all_db_list)
